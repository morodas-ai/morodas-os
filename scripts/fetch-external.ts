/**
 * fetch-external.ts â€” å¤–éƒ¨ã‚½ãƒ¼ã‚¹å–å¾—CLI
 *
 * Reddit / Hacker News / arXiv / Dev.to ã‹ã‚‰
 * æŒ‡å®šã—ãŸã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã«é–¢ã™ã‚‹æœ€æ–°æƒ…å ±ã‚’å–å¾—ã™ã‚‹ã€‚
 * ã™ã¹ã¦ç„¡æ–™APIã€‚Xï¼ˆTwitterï¼‰ã¯ä½¿ç”¨ã—ãªã„ã€‚
 *
 * ä½¿ã„æ–¹:
 *   npx tsx scripts/fetch-external.ts "Chrome MCP Server"
 *   npx tsx scripts/fetch-external.ts "OpenClaw" --source reddit
 *   npx tsx scripts/fetch-external.ts "MCP" --source hackernews
 *   npx tsx scripts/fetch-external.ts "tool use LLM" --source arxiv
 *   npx tsx scripts/fetch-external.ts "ai agent" --source devto
 */

// --- å‹å®šç¾© ---

interface ExternalResult {
    source: string;
    title: string;
    url: string;
    date: string;
    score?: number;
    summary: string;
}

interface FetchOutput {
    query: string;
    fetched_at: string;
    sources_requested: string[];
    total_results: number;
    results: Record<string, ExternalResult[]>;
    errors: Record<string, string>;
}

// --- CLIå¼•æ•°ãƒ‘ãƒ¼ã‚¹ ---

type SourceName = "reddit" | "hackernews" | "arxiv" | "devto";
const ALL_SOURCES: SourceName[] = ["reddit", "hackernews", "arxiv", "devto"];

function parseArgs(): { query: string; sources: SourceName[] } {
    const args = process.argv.slice(2);

    if (args.length < 1) {
        console.error(`
ä½¿ã„æ–¹:
  npx tsx scripts/fetch-external.ts "æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰" [--source ã‚½ãƒ¼ã‚¹å]

ã‚½ãƒ¼ã‚¹:
  reddit       Reddit ã®é–¢é€£æŠ•ç¨¿
  hackernews   Hacker News ã®ã‚¹ãƒˆãƒ¼ãƒªãƒ¼ï¼‹ã‚³ãƒ¡ãƒ³ãƒˆ
  arxiv        arXiv ã®æœ€æ–°é–¢é€£è«–æ–‡
  devto        Dev.to ã®ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«è¨˜äº‹

--source ã‚’çœç•¥ã™ã‚‹ã¨å…¨ã‚½ãƒ¼ã‚¹ã‹ã‚‰ä¸€æ‹¬å–å¾—ã—ã¾ã™ã€‚
`);
        process.exit(1);
    }

    const query = args[0];
    let sources: SourceName[] = [...ALL_SOURCES];

    const srcIdx = args.indexOf("--source");
    if (srcIdx !== -1 && args[srcIdx + 1]) {
        const requested = args[srcIdx + 1].toLowerCase() as SourceName;
        if (!ALL_SOURCES.includes(requested)) {
            console.error(`âŒ ä¸æ˜ãªã‚½ãƒ¼ã‚¹: "${requested}". ä½¿ãˆã‚‹ã‚½ãƒ¼ã‚¹: ${ALL_SOURCES.join(", ")}`);
            process.exit(1);
        }
        sources = [requested];
    }

    return { query, sources };
}

// --- ãƒ•ã‚§ãƒƒãƒãƒ£ãƒ¼ ---

async function fetchReddit(query: string): Promise<ExternalResult[]> {
    // old.reddit.com + ãƒ–ãƒ©ã‚¦ã‚¶é¢¨User-Agentã§403å›é¿
    const url = `https://old.reddit.com/search.json?q=${encodeURIComponent(query)}&sort=relevance&t=month&limit=10`;
    const res = await fetch(url, {
        headers: {
            "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36",
            "Accept": "application/json",
        },
    });

    if (!res.ok) throw new Error(`Reddit API error: ${res.status}`);
    const data = await res.json();

    const children = data?.data?.children || [];
    return children.map((child: Record<string, unknown>) => {
        const d = child.data as Record<string, unknown>;
        return {
            source: "reddit",
            title: (d.title as string) || "",
            url: `https://reddit.com${d.permalink as string}`,
            date: new Date(((d.created_utc as number) || 0) * 1000).toISOString().split("T")[0],
            score: (d.score as number) || 0,
            summary: ((d.selftext as string) || "").slice(0, 300),
        };
    });
}

async function fetchHackerNews(query: string): Promise<ExternalResult[]> {
    const url = `https://hn.algolia.com/api/v1/search?query=${encodeURIComponent(query)}&tags=story&hitsPerPage=10`;
    const res = await fetch(url);

    if (!res.ok) throw new Error(`HN API error: ${res.status}`);
    const data = await res.json();

    const hits = data?.hits || [];
    return hits.map((hit: Record<string, unknown>) => ({
        source: "hackernews",
        title: (hit.title as string) || "",
        url: (hit.url as string) || `https://news.ycombinator.com/item?id=${hit.objectID}`,
        date: ((hit.created_at as string) || "").split("T")[0],
        score: (hit.points as number) || 0,
        summary: `${hit.num_comments || 0} comments, ${hit.points || 0} points`,
    }));
}

async function fetchArxiv(query: string): Promise<ExternalResult[]> {
    const url = `http://export.arxiv.org/api/query?search_query=all:${encodeURIComponent(query)}&max_results=5&sortBy=submittedDate&sortOrder=descending`;
    const res = await fetch(url);

    if (!res.ok) throw new Error(`arXiv API error: ${res.status}`);
    const text = await res.text();

    // arXiv returns Atom XML â€” simple regex extraction
    const entries: ExternalResult[] = [];
    const entryRegex = /<entry>([\s\S]*?)<\/entry>/g;
    let match;

    while ((match = entryRegex.exec(text)) !== null) {
        const entry = match[1];
        const getTag = (tag: string): string => {
            const m = entry.match(new RegExp(`<${tag}[^>]*>([\\s\\S]*?)<\\/${tag}>`));
            return m ? m[1].trim() : "";
        };
        const getAttr = (tag: string, attr: string): string => {
            const m = entry.match(new RegExp(`<${tag}[^>]*${attr}="([^"]*)"[^>]*/>`));
            return m ? m[1] : "";
        };

        // Get PDF link
        let paperUrl = getAttr("link", "href");
        const pdfLink = entry.match(/<link[^>]*title="pdf"[^>]*href="([^"]*)"[^>]*\/>/);
        if (pdfLink) paperUrl = pdfLink[1];
        if (!paperUrl) {
            const idMatch = entry.match(/<id>([\s\S]*?)<\/id>/);
            paperUrl = idMatch ? idMatch[1].trim() : "";
        }

        entries.push({
            source: "arxiv",
            title: getTag("title").replace(/\s+/g, " "),
            url: paperUrl,
            date: getTag("published").split("T")[0],
            summary: getTag("summary").replace(/\s+/g, " ").slice(0, 400),
        });
    }

    return entries;
}

async function fetchDevTo(query: string): Promise<ExternalResult[]> {
    // Dev.to API doesn't support multi-word tag search well, so use per_page with query
    const url = `https://dev.to/api/articles?per_page=5&tag=${encodeURIComponent(query.replace(/\s+/g, "").toLowerCase())}`;
    const res = await fetch(url);

    if (!res.ok) {
        // Fallback: search by title/body
        const fallbackUrl = `https://dev.to/api/articles?per_page=5&tag=ai`;
        const fallbackRes = await fetch(fallbackUrl);
        if (!fallbackRes.ok) throw new Error(`Dev.to API error: ${res.status}`);
        const data = await fallbackRes.json();
        return (data as Array<Record<string, unknown>>).map((article) => ({
            source: "devto",
            title: (article.title as string) || "",
            url: (article.url as string) || "",
            date: ((article.published_at as string) || "").split("T")[0],
            score: (article.positive_reactions_count as number) || 0,
            summary: (article.description as string) || "",
        }));
    }

    const data = await res.json();
    return (data as Array<Record<string, unknown>>).map((article) => ({
        source: "devto",
        title: (article.title as string) || "",
        url: (article.url as string) || "",
        date: ((article.published_at as string) || "").split("T")[0],
        score: (article.positive_reactions_count as number) || 0,
        summary: (article.description as string) || "",
    }));
}

// --- ã‚½ãƒ¼ã‚¹ãƒ‡ã‚£ã‚¹ãƒ‘ãƒƒãƒ ---

const FETCHERS: Record<SourceName, (q: string) => Promise<ExternalResult[]>> = {
    reddit: fetchReddit,
    hackernews: fetchHackerNews,
    arxiv: fetchArxiv,
    devto: fetchDevTo,
};

// --- ãƒ¡ã‚¤ãƒ³ ---

async function main() {
    const { query, sources } = parseArgs();

    console.error(`ğŸŒ å¤–éƒ¨ã‚½ãƒ¼ã‚¹å–å¾—: "${query}"`);
    console.error(`ğŸ“¡ å¯¾è±¡ã‚½ãƒ¼ã‚¹: ${sources.join(", ")}\n`);

    const output: FetchOutput = {
        query,
        fetched_at: new Date().toISOString(),
        sources_requested: sources,
        total_results: 0,
        results: {},
        errors: {},
    };

    for (const source of sources) {
        console.error(`  â³ ${source} ã‚’å–å¾—ä¸­...`);
        try {
            const results = await FETCHERS[source](query);
            output.results[source] = results;
            output.total_results += results.length;
            console.error(`  âœ… ${source}: ${results.length}ä»¶`);
        } catch (err) {
            const msg = err instanceof Error ? err.message : String(err);
            output.errors[source] = msg;
            output.results[source] = [];
            console.error(`  âŒ ${source}: ${msg}`);
        }
    }

    console.log(JSON.stringify(output, null, 2));
    console.error(`\nâœ… å®Œäº†ï¼åˆè¨ˆ ${output.total_results}ä»¶ã‚’å–å¾—ã—ã¾ã—ãŸã€‚`);
}

main().catch((err) => {
    console.error("âŒ ã‚¨ãƒ©ãƒ¼:", err.message || err);
    process.exit(1);
});
